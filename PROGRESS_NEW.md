Zenodo Image Browser - Project Status & Architectural Overview
📌 AI Agent Instructions
> This document is a living snapshot of the project's architecture, key decisions, and development roadmap.
> Use this file as the primary source of truth for the current state of the codebase. It maps features to the specific modules and functions that implement them. When asked to add a feature or fix a bug, refer to the Architectural Deep Dive to understand where the changes should be made and to the Technical Decisions Log to follow established patterns.
> 
🎯 Current Status Summary (As of July 2025)
The Zenodo Image Browser has successfully transitioned from a prototype with simulated data to a fully functional scientific analysis platform. The core image processing pipeline is implemented and validated, processing real images directly from Zenodo datasets. All major stability issues and dependency conflicts from the initial build have been resolved.
 * Key Achievement: Real-time, on-demand analysis of scientific images.
 * Primary Validation Case: All features have been tested and validated using experimental fluid mechanics images from Zenodo Record 7890690.
🏗️ Architectural Deep Dive & Feature Mapping
This section details the core components of the application and maps completed features to their location in the codebase.
1. Frontend: Streamlit UI (@app.py)
The main user-facing application for interaction and visualization.
 * Interactive Controls: Contains Streamlit widgets (st.slider, st.selectbox) for adjusting analysis parameters in real-time.
 * Visualization Display: Uses st.image and st.pyplot to render "before/after" image comparisons and statistical plots generated by the processing pipeline.
 * API Client Logic: Makes requests calls to the FastAPI backend to trigger analysis and fetch data.
 * User Feedback: Implements st.spinner for loading indicators and st.success/st.error for user notifications.
2. Backend: FastAPI Server (@src/main.py)
The processing workhorse that serves data and runs analyses via API endpoints.
 * /fetch-zenodo-record Endpoint: Connects to the Zenodo API client to retrieve dataset metadata and file lists.
 * /analyze/{analysis_type} Endpoints: Routes requests to the appropriate image processing functions (e.g., /analyze/edge-detection).
 * Error Handling: Implements robust try...except blocks to catch processing failures and return meaningful error messages to the frontend.
3. Core Image Processing Pipeline (@src/analysis/)
This is where the main scientific computations happen. The standard function signature is process_x(image: np.ndarray, **kwargs) -> dict.
 * Image Info (@src/analysis/image_info.py)
   * Key Function: get_basic_image_info(image)
   * Capabilities: Extracts real image dimensions, color mode (RGB/grayscale), aspect ratio, and estimates memory usage.
   * Status: ✅ Implemented.
 * Edge Detection (@src/analysis/edge_detection.py)
   * Key Function: process_canny_edge(image, lower_thresh, upper_thresh)
   * Capabilities: Downloads image from URL, applies Gaussian blur, performs OpenCV Canny edge detection, and calculates statistics (edge pixel count, density, contours).
   * Status: ✅ Implemented and validated.
 * Color Analysis (@src/analysis/color_analysis.py)
   * Key Function: process_color_analysis(image)
   * Capabilities: Calculates per-channel (RGB) statistics (mean, std), determines dominant colors, and generates color distribution histograms with Matplotlib.
   * Status: ✅ Implemented.
4. AI Assistant & Data Access (@src/api/)
Handles communication with external services and the AI's understanding of the data.
 * Zenodo API Client (@src/api/zenodo_client.py)
   * Purpose: The sole module responsible for communicating with the Zenodo API.
   * Key Function: fetch_files_from_record(record_id)
   * Status: ✅ Implemented.
 * MCP Server / AI Context (@src/mcp_server.py)
   * Purpose: Provides context to the AI model, allowing it to reason about the available tools and data.
   * Capabilities: Can now query real Zenodo datasets and suggest analysis based on file metadata (e.g., "This is a PNG, would you like to run edge detection?").
   * Status: ✅ Basic implementation complete.
📝 Key Technical Decisions & Rules Log
This log captures important constraints and patterns that all new development must follow.
 * Dependency Rule: scikit-image Versioning
   * Decision: An early version conflict was resolved. The project now uses the peak_local_max function.
   * Rule: Do not use the deprecated peak_local_maxima function. All new code must use peak_local_max.
 * API Data Model: Zenodo File Key
   * Decision: The Zenodo API uses the 'key' field for filenames within a record, not 'name'.
   * Rule: All logic in @src/api/zenodo_client.py and any function that processes Zenodo file metadata must access the filename via the 'key' dictionary field.
 * UI/Backend Separation
   * Decision: Heavy processing must never occur on the Streamlit thread. All analysis is delegated to the FastAPI backend.
   * Rule: The app.py file should only contain UI code and API calls. All OpenCV or heavy numpy logic belongs in the @src/analysis/ directory and should be exposed via an endpoint in @src/main.py.
🚀 Roadmap & Actionable Next Steps
This section outlines future work as concrete, AI-assistable development tasks.
🎯 Immediate Priorities (Next 1-2 Weeks)
 * Optimize Canny Edge Detection Performance
   * Objective: The process_canny_edge function is slow on large images (>2048x2048). Investigate resizing options or more efficient contour detection methods.
   * Files to Modify: @src/analysis/edge_detection.py.
   * AI Task: "Analyze the function process_canny_edge in @src/analysis/edge_detection.py. Suggest specific optimizations to improve its performance for high-resolution images. Let's start by adding an optional resizing step before the cv2.Canny call."
 * Create User-Facing Documentation
   * Objective: Write a simple guide explaining how to use the analysis tools.
   * Files to Modify: Create a new file TUTORIAL.md.
   * AI Task: "Using the information in @src/analysis/, generate a section for TUTORIAL.md that explains the 'Edge Detection' tool. Describe what it does, what the sliders control, and how to interpret the results."
🌟 Long-term Vision (Next 3-6 Weeks)
 * Integrate a Machine Learning Classification Model
   * Objective: Add the ability to classify image patterns (e.g., "lamellar," "dendritic").
   * Architectural Plan:
     * Create a new module src/models/pattern_classifier.py to house the PyTorch model loading and prediction logic.
     * Add a new endpoint /predict/pattern to src/main.py that accepts an image and returns a classification result.
     * Add a new button and result display in app.py to call this new endpoint.
   * AI Task: "Help me draft the boilerplate for a new endpoint /predict/pattern in @src/main.py. It should call a function classify_pattern from a new file, @src/models/pattern_classifier.py."
 * Implement User Accounts & Shared Workspaces
   * Objective: Allow users to save their analysis results and collaborate.
   * Architectural Plan: This will require adding a database (e.g., SQLite or PostgreSQL) and authentication logic (e.g., FastAPI-Users). This is a major epic.
   * AI Task: "Help me select a suitable library for adding user authentication to a FastAPI application and outline the necessary changes to @src/main.py."

Great! Here’s how you can test the new ZIP extraction logic locally:

---

### **How to Test the ZIP Extraction**

1. **Open a Python shell or create a test script** in your project directory.

2. **Import and instantiate the ZenodoAPI:**
   ```python
   from src.api.zenodo import ZenodoAPI

   zenodo = ZenodoAPI()  # Make sure your ZENODO_API_KEY is set in your .env file if needed
   ```

3. **Call the new `get_files` method with a Zenodo record ID that contains a ZIP file:**
   ```python
   record_id = "YOUR_RECORD_ID"  # Replace with a real record ID containing a ZIP
   files = zenodo.get_files(record_id)
   for f in files:
       print(f)
   ```

4. **What to look for:**
   - You should see both the top-level files and entries for files inside any ZIP archives.
   - Extracted files will have keys like `"archive.zip/innerfile.png"` and include `"from_zip": True`.

---

### **If you want a quick test script:**

Create a file called `test_zip_extraction.py` in your project root with:
```python
from src.api.zenodo import ZenodoAPI

zenodo = ZenodoAPI()
record_id = "YOUR_RECORD_ID"  # Replace with a real record ID containing a ZIP
files = zenodo.get_files(record_id)
for f in files:
    print(f)
```
Then run:
```bash
<code_block_to_apply_changes_from>
python test_zip_extraction.py
```

---

**Let me know the results or if you encounter any errors!**  
If you need a real Zenodo record ID with a ZIP, I can suggest one, or you can use one from your own datasets.

Absolutely—that’s the next logical step! Now that ZIP extraction works in the backend, you should:

1. **Run your Streamlit app** as usual:
   ```bash
   streamlit run app.py
   ```

2. **Open a Zenodo record (e.g., 3518067) in the app.**
   - Check if the file list now includes both the ZIP file and its extracted contents.
   - See if you can select and analyze files from inside the ZIP just like regular files.

3. **What to look for:**
   - Are ZIP contents clearly listed and selectable?
   - Does the analysis pipeline work for files inside ZIPs?
   - Is there any UI confusion or error when handling these files?

---

**If you encounter any issues:**
- Let me know what you see (screenshots, error messages, or unexpected behavior).
- I can help you update the frontend to better display or handle ZIP contents if needed.

Ready to launch the app and try it out? If you want, I can run the command for you!
